name: Tests

on:
  workflow_dispatch:
  push:
    branches: [main]
    paths:
      - "src/**"
      - "dist/**"
      - "action.yml"
      - "__fixtures__/**"
      - "./.github/actions/test-fixture/**"
      - ".github/workflows/test.yml"
  pull_request:
    paths:
      - "src/**"
      - "dist/**"
      - "action.yml"
      - "__fixtures__/**"
      - "./.github/actions/test-fixture/**"
      - ".github/workflows/test.yml"

jobs:
  # ============================================================================
  # Node.js Tests
  # ============================================================================
  test-node:
    name: Node.js - ${{ matrix.name }} (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        include:
          - name: NPM
            fixture: node-minimal
            package-manager: npm
            expected-node-enabled: "true"
            expected-package-manager: npm
            test-command: "node --version && npm --version"
            title: "ðŸ“¦ NPM Test Results"

          - name: PNPM
            fixture: node-pnpm
            expected-node-enabled: "true"
            expected-package-manager: pnpm
            test-command: "node --version && pnpm --version"
            title: "ðŸ“¦ PNPM Test Results"

          - name: Yarn
            fixture: node-yarn
            expected-node-enabled: "true"
            expected-package-manager: yarn
            test-command: "node --version && yarn --version"
            title: "ðŸ“¦ Yarn Test Results"

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Test fixture
        id: test
        uses: ./.github/actions/test-fixture
        with:
          fixture: ${{ matrix.fixture }}
          title: ${{ matrix.title }}
          package-manager: ${{ matrix.package-manager || '' }}
          install-deps: "true"
          expected-node-enabled: ${{ matrix.expected-node-enabled || '' }}
          expected-package-manager: ${{ matrix.expected-package-manager || '' }}

      - name: Test runtime
        if: matrix.test-command != ''
        run: ${{ matrix.test-command }}

      - name: Save test results
        if: always()
        shell: bash
        run: |
          mkdir -p test-results

          # Set defaults for missing outputs
          PASSED="${{ steps.test.outputs.test-passed }}"
          RESULTS="${{ steps.test.outputs.test-results }}"
          PASSED="${PASSED:-false}"
          RESULTS="${RESULTS:-{}}"

          cat > "test-results/${{ matrix.name }}.json" <<EOF
          {
            "name": "${{ matrix.name }}",
            "title": "${{ matrix.title }}",
            "fixture": "${{ matrix.fixture }}",
            "passed": $PASSED,
            "results": $RESULTS
          }
          EOF

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-node-${{ matrix.os }}-${{ strategy.job-index }}
          path: test-results/
          retention-days: 1

  # ============================================================================
  # Bun Tests
  # ============================================================================
  test-bun:
    name: Bun - ${{ matrix.name }} (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        include:
          - name: From devEngines
            fixture: bun-minimal
            expected-bun-enabled: "true"
            expected-package-manager: bun
            test-command: "bun --version && bun run index.ts"
            title: "ðŸš€ Bun from devEngines Test Results"

          - name: Explicit Version
            fixture: bun-minimal
            package-manager: bun
            package-manager-version: "1.3.3"
            bun-version: "1.3.3"
            expected-bun-enabled: "true"
            expected-bun-version: "1.3.3"
            test-command: "bun --version && bun run test.js"
            title: "ðŸŽ¯ Bun Explicit Version Test Results"

          - name: Lockfile
            fixture: bun-lockfile
            test-command: "bun --version"
            verify-lockfile: bun.lock
            title: "ðŸ”’ Bun Lockfile Test Results"

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Test fixture
        id: test
        uses: ./.github/actions/test-fixture
        with:
          fixture: ${{ matrix.fixture }}
          title: ${{ matrix.title }}
          package-manager: ${{ matrix.package-manager || '' }}
          bun-version: ${{ matrix.bun-version || '' }}
          install-deps: "true"
          expected-bun-enabled: ${{ matrix.expected-bun-enabled || '' }}
          expected-bun-version: ${{ matrix.expected-bun-version || '' }}
          expected-package-manager: ${{ matrix.expected-package-manager || '' }}

      - name: Test runtime
        if: matrix.test-command != ''
        run: ${{ matrix.test-command }}

      - name: Verify lockfile
        id: verify-lockfile
        if: matrix.verify-lockfile != ''
        continue-on-error: true
        shell: bash
        run: |
          if [ ! -f "${{ matrix.verify-lockfile }}" ]; then
            echo "lockfile-verified=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "lockfile-verified=true" >> $GITHUB_OUTPUT

      - name: Save test results
        if: always()
        shell: bash
        run: |
          mkdir -p test-results

          # Set defaults for missing outputs
          PASSED="${{ steps.test.outputs.test-passed }}"
          RESULTS="${{ steps.test.outputs.test-results }}"
          PASSED="${PASSED:-false}"
          RESULTS="${RESULTS:-{}}"

          cat > "test-results/${{ matrix.name }}.json" <<EOF
          {
            "name": "${{ matrix.name }}",
            "title": "${{ matrix.title }}",
            "fixture": "${{ matrix.fixture }}",
            "passed": $PASSED,
            "lockfile_verified": "${{ steps.verify-lockfile.outputs.lockfile-verified || 'n/a' }}",
            "results": $RESULTS
          }
          EOF

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-bun-${{ matrix.os }}-${{ strategy.job-index }}
          path: test-results/
          retention-days: 1

  # ============================================================================
  # Deno Tests
  # ============================================================================
  test-deno:
    name: Deno - ${{ matrix.name }} (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        include:
          - name: Explicit Input
            fixture: deno-minimal
            deno-version: "1.3.3"
            package-manager: deno
            package-manager-version: "1.3.3"
            expected-deno-enabled: "true"
            expected-package-manager: deno
            expected-package-manager-version: "1.3.3"
            expected-deno-version: "1.3.3"
            test-command: "deno --version && deno run main.ts"
            title: "ðŸ¦• Deno Explicit Input Test Results"

          - name: From devEngines
            fixture: deno-lockfile
            expected-deno-enabled: "true"
            expected-package-manager: npm
            expected-deno-version: "2.5.6"
            test-command: "deno run app.ts"
            title: "ðŸ“¦ Deno from devEngines Test Results"

          - name: Explicit Version
            fixture: deno-minimal
            package-manager: deno
            package-manager-version: "1.3.3"
            deno-version: "1.3.3"
            expected-deno-enabled: "true"
            expected-deno-version: "1.3.3"
            expected-package-manager: deno
            test-command: "deno --version && deno run test.ts"
            title: "ðŸŽ¯ Deno Explicit Version Test Results"

          - name: Lockfile
            fixture: deno-lockfile
            package-manager: deno
            package-manager-version: "2.5.6"
            deno-version: "2.5.6"
            test-command: "deno run main.ts"
            verify-lockfile: deno.lock
            expected-deno-enabled: "true"
            expected-deno-version: "2.5.6"
            expected-package-manager: deno
            title: "ðŸ”’ Deno Lockfile Test Results"

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Test fixture
        id: test
        uses: ./.github/actions/test-fixture
        with:
          fixture: ${{ matrix.fixture }}
          title: ${{ matrix.title }}
          package-manager: ${{ matrix.package-manager || '' }}
          deno-version: ${{ matrix.deno-version || '' }}
          install-deps: "true"
          expected-deno-enabled: ${{ matrix.expected-deno-enabled || '' }}
          expected-deno-version: ${{ matrix.expected-deno-version || '' }}
          expected-package-manager: ${{ matrix.expected-package-manager || '' }}

      - name: Test runtime
        if: matrix.test-command != ''
        run: ${{ matrix.test-command }}

      - name: Verify lockfile
        id: verify-lockfile
        if: matrix.verify-lockfile != ''
        continue-on-error: true
        shell: bash
        run: |
          if [ ! -f "${{ matrix.verify-lockfile }}" ]; then
            echo "lockfile-verified=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "lockfile-verified=true" >> $GITHUB_OUTPUT

      - name: Save test results
        if: always()
        shell: bash
        run: |
          mkdir -p test-results

          # Set defaults for missing outputs
          PASSED="${{ steps.test.outputs.test-passed }}"
          RESULTS="${{ steps.test.outputs.test-results }}"
          PASSED="${PASSED:-false}"
          RESULTS="${RESULTS:-{}}"

          cat > "test-results/${{ matrix.name }}.json" <<EOF
          {
            "name": "${{ matrix.name }}",
            "title": "${{ matrix.title }}",
            "fixture": "${{ matrix.fixture }}",
            "passed": $PASSED,
            "lockfile_verified": "${{ steps.verify-lockfile.outputs.lockfile-verified || 'n/a' }}",
            "results": $RESULTS
          }
          EOF

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-deno-${{ matrix.os }}-${{ strategy.job-index }}
          path: test-results/
          retention-days: 1

  # ============================================================================
  # Feature Tests
  # ============================================================================
  test-features:
    name: Features - ${{ matrix.name }} (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        include:
          - name: Biome from Config
            fixture: biome-auto
            expected-biome-enabled: "true"
            expected-biome-version: "2.3.6"
            test-command: "biome --version"
            title: "ðŸ§¬ Biome from Config Test Results"

          - name: Biome Explicit Version
            fixture: node-minimal
            biome-version: "2.3.6"
            expected-biome-enabled: "true"
            expected-biome-version: "2.3.6"
            test-command: "biome --version"
            title: "ðŸŽ¯ Biome Explicit Version Test Results"

          - name: Turbo Detection
            fixture: turbo-monorepo
            expected-turbo-enabled: "true"
            test-command: "echo 'Turbo detected'"
            title: "âš¡ Turbo Detection Test Results"

          - name: Skip Dependencies
            fixture: cache-test
            install-deps: "false"
            test-command: "node --version && npm --version"
            verify-no-node-modules: "true"
            title: "ðŸš« Skip Dependencies Test Results"

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Test fixture
        id: test
        uses: ./.github/actions/test-fixture
        with:
          fixture: ${{ matrix.fixture }}
          title: ${{ matrix.title }}
          biome-version: ${{ matrix.biome-version || '' }}
          install-deps: ${{ matrix.install-deps || 'true' }}
          expected-biome-enabled: ${{ matrix.expected-biome-enabled || '' }}
          expected-biome-version: ${{ matrix.expected-biome-version || '' }}
          expected-turbo-enabled: ${{ matrix.expected-turbo-enabled || '' }}

      - name: Test runtime
        if: matrix.test-command != ''
        run: ${{ matrix.test-command }}

      - name: Verify no node_modules
        id: verify-no-modules
        if: matrix.verify-no-node-modules == 'true'
        continue-on-error: true
        shell: bash
        run: |
          if [ -d "node_modules" ]; then
            echo "no-modules-verified=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "no-modules-verified=true" >> $GITHUB_OUTPUT

      - name: Save test results
        if: always()
        shell: bash
        run: |
          mkdir -p test-results

          # Set defaults for missing outputs
          PASSED="${{ steps.test.outputs.test-passed }}"
          RESULTS="${{ steps.test.outputs.test-results }}"
          NO_MODULES="${{ steps.verify-no-modules.outputs.no-modules-verified || 'n/a' }}"
          PASSED="${PASSED:-false}"
          RESULTS="${RESULTS:-{}}"

          # If we have no_modules verification, we need to check it for overall pass/fail
          if [ "$NO_MODULES" != "n/a" ] && [ "$NO_MODULES" != "true" ]; then
            PASSED="false"
          fi

          # Add no_modules_verified to results if it was checked
          if [ "$NO_MODULES" != "n/a" ]; then
            # Remove trailing } from RESULTS and add the new field
            RESULTS="${RESULTS%\}}"
            if [ "$RESULTS" != "{" ]; then
              RESULTS="$RESULTS,"
            fi
            RESULTS="$RESULTS\"no-node-modules\":{\"actual\":\"$NO_MODULES\",\"expected\":\"true\",\"status\":\"$( [ "$NO_MODULES" = "true" ] && echo "passed" || echo "failed" )\"}"
          fi

          cat > "test-results/${{ matrix.name }}.json" <<EOF
          {
            "name": "${{ matrix.name }}",
            "title": "${{ matrix.title }}",
            "fixture": "${{ matrix.fixture }}",
            "passed": $PASSED,
            "results": $RESULTS
          }
          EOF

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-features-${{ matrix.os }}-${{ strategy.job-index }}
          path: test-results/
          retention-days: 1

  # ============================================================================
  # Cache Test
  # ============================================================================
  test-cache:
    name: Cache - ${{ matrix.name }} (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        include:
          - name: "Cache Effectiveness"
            fixture: "cache-test"
            title: "ðŸ’¾ Cache Effectiveness Test Results"
            expected-node-version: "20.11.0"
            expected-package-manager: "npm"
            expected-package-manager-version: "10.2.4"
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Test with cache
        id: test
        uses: ./.github/actions/test-fixture
        with:
          fixture: ${{ matrix.fixture }}
          title: ${{ matrix.title }}
          test-cache: "true"
          expected-node-version: ${{ matrix.expected-node-version }}
          expected-package-manager: ${{ matrix.expected-package-manager }}
          expected-package-manager-version: ${{ matrix.expected-package-manager-version }}

      - name: Save test results
        if: always()
        shell: bash
        run: |
          mkdir -p test-results
          cat > "test-results/${{ matrix.name }}.json" <<EOF
          {
            "name": "${{ matrix.name }}",
            "title": "${{ matrix.title }}",
            "fixture": "${{ matrix.fixture }}",
            "passed": ${{ steps.test.outputs.test-passed }},
            "results": ${{ steps.test.outputs.test-results }}
          }
          EOF

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-cache-${{ matrix.os }}-${{ strategy.job-index }}
          path: test-results/
          retention-days: 1

  # ============================================================================
  # Test Summary
  # ============================================================================
  summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-node, test-bun, test-deno, test-features, test-cache]
    if: always()
    steps:
      - name: Download all test results
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          path: all-results
          merge-multiple: true

      - name: Generate aggregated summary
        shell: bash
        run: |
          echo "## ðŸ§ª Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          TOTAL=0
          PASSED=0
          FAILED=0
          SKIPPED=0
          PARSE_ERRORS=()

          # Create directory if it doesn't exist
          mkdir -p all-results

          # Check if there are any test results
          if [ ! "$(ls -A all-results/*.json 2>/dev/null)" ]; then
            echo "âš ï¸ No test results found - all test jobs may have failed before uploading results." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

          # Process all JSON result files
          for file in all-results/*.json; do
            if [ -f "$file" ]; then
              # Try to validate JSON first
              if ! jq empty "$file" 2>/dev/null; then
                SKIPPED=$((SKIPPED + 1))
                PARSE_ERRORS+=("$(basename "$file")")
                echo "âš ï¸ Skipping malformed JSON: $(basename "$file")" >&2
                continue
              fi

              TOTAL=$((TOTAL + 1))

              # Extract test info (with error handling)
              name=$(jq -r '.name // "Unknown"' "$file" 2>/dev/null || echo "Unknown")
              title=$(jq -r '.title // "Unknown"' "$file" 2>/dev/null || echo "Unknown")
              fixture=$(jq -r '.fixture // "Unknown"' "$file" 2>/dev/null || echo "Unknown")
              passed=$(jq -r '.passed // "false"' "$file" 2>/dev/null || echo "false")

              # Count passes/fails
              if [ "$passed" == "true" ]; then
                PASSED=$((PASSED + 1))
                status="âœ…"
              else
                FAILED=$((FAILED + 1))
                status="âŒ"
              fi

              # Show test with title
              echo "### $status $title" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY

              # Add expandable details
              echo "<details>" >> $GITHUB_STEP_SUMMARY
              if [ "$passed" == "true" ]; then
                echo "<summary>$name</summary>" >> $GITHUB_STEP_SUMMARY
              else
                echo "<summary>$name (failed)</summary>" >> $GITHUB_STEP_SUMMARY
              fi
              echo "" >> $GITHUB_STEP_SUMMARY

              # Show test metadata
              echo "**Fixture:** \`$fixture\`" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY

              # Parse and display results (with error handling)
              results=$(jq -r '.results // {}' "$file" 2>/dev/null || echo "{}")
              if [ "$results" != "{}" ]; then
                echo "**Results:**" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "| Output | Actual | Expected | Status |" >> $GITHUB_STEP_SUMMARY
                echo "|--------|--------|----------|--------|" >> $GITHUB_STEP_SUMMARY

                # Iterate through each result (with error handling)
                if jq -e '.results' "$file" >/dev/null 2>&1; then
                  jq -r '.results | to_entries | .[] | "\(.key)|\(.value.actual)|\(.value.expected)|\(.value.status)"' "$file" 2>/dev/null | while IFS='|' read -r key actual expected status; do
                  # Format status with emoji
                  case "$status" in
                    passed) status_icon="âœ…" ;;
                    failed) status_icon="âŒ" ;;
                    info) status_icon="â„¹ï¸" ;;
                    *) status_icon="â€”" ;;
                  esac

                  # Handle empty expected
                  if [ -z "$expected" ]; then
                    expected="â€”"
                  fi

                  echo "| \`$key\` | \`$actual\` | \`$expected\` | $status_icon |" >> $GITHUB_STEP_SUMMARY
                  done
                fi
              fi

              # Show additional verification info if present (with error handling)
              lockfile_verified=$(jq -r '.lockfile_verified // "n/a"' "$file" 2>/dev/null || echo "n/a")
              no_modules_verified=$(jq -r '.no_modules_verified // "n/a"' "$file" 2>/dev/null || echo "n/a")
              deps_verified=$(jq -r '.deps_verified // "n/a"' "$file" 2>/dev/null || echo "n/a")
              cache_verified=$(jq -r '.cache_verified // "n/a"' "$file" 2>/dev/null || echo "n/a")

              if [ "$lockfile_verified" != "n/a" ] || [ "$no_modules_verified" != "n/a" ] || [ "$deps_verified" != "n/a" ] || [ "$cache_verified" != "n/a" ]; then
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "**Additional Verifications:**" >> $GITHUB_STEP_SUMMARY
                [ "$lockfile_verified" != "n/a" ] && echo "- Lockfile verified: $lockfile_verified" >> $GITHUB_STEP_SUMMARY
                [ "$no_modules_verified" != "n/a" ] && echo "- No modules verified: $no_modules_verified" >> $GITHUB_STEP_SUMMARY
                [ "$deps_verified" != "n/a" ] && echo "- Dependencies verified: $deps_verified" >> $GITHUB_STEP_SUMMARY
                [ "$cache_verified" != "n/a" ] && echo "- Cache verified: $cache_verified" >> $GITHUB_STEP_SUMMARY
              fi

              # Add raw JSON section (with error handling)
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "<details>" >> $GITHUB_STEP_SUMMARY
              echo "<summary>Raw Test Data (JSON)</summary>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
              if jq '.' "$file" >> $GITHUB_STEP_SUMMARY 2>/dev/null; then
                :  # Success, do nothing
              else
                echo "Error: Could not format JSON" >> $GITHUB_STEP_SUMMARY
                cat "$file" >> $GITHUB_STEP_SUMMARY
              fi
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY

              echo "" >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          done

          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Report parse errors if any
          if [ ${#PARSE_ERRORS[@]} -gt 0 ]; then
            echo "### âš ï¸ Parse Errors" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The following test result files could not be parsed (likely due to job failures):" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            for error_file in "${PARSE_ERRORS[@]}"; do
              echo "- \`$error_file\`" >> $GITHUB_STEP_SUMMARY
            done
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "---" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Final summary
          if [ $FAILED -eq 0 ] && [ $SKIPPED -eq 0 ]; then
            echo "### âœ… All $TOTAL tests passed!" >> $GITHUB_STEP_SUMMARY
            exit 0
          elif [ $TOTAL -eq 0 ]; then
            echo "### âš ï¸ No valid test results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Skipped:** $SKIPPED (malformed JSON)" >> $GITHUB_STEP_SUMMARY
            exit 1
          else
            echo "### âŒ $FAILED of $TOTAL tests failed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Passed:** $PASSED / **Failed:** $FAILED / **Total:** $TOTAL" >> $GITHUB_STEP_SUMMARY
            if [ $SKIPPED -gt 0 ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "âš ï¸ **Skipped:** $SKIPPED test(s) with malformed JSON" >> $GITHUB_STEP_SUMMARY
            fi
            exit 1
          fi
